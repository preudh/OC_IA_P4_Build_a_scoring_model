{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Load the Preprocessed Data",
   "id": "458083ce2249405a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Indicate if the script is running on Google Colab or not\n",
    "using_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if using_colab:\n",
    "    # Connect Google Drive to Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    \n",
    "    # Install necessary packages\n",
    "    !pip install numpy\n",
    "    !pip install pandas\n",
    "    !pip install sklearn\n",
    "    !pip install matplotlib\n",
    "    !pip install seaborn\n",
    "    !pip install imbalanced-learn\n",
    "    \n",
    "    # Path for Google Colab\n",
    "    project_root = '/content/gdrive/MyDrive/oc_projet_4/' \n",
    "else:\n",
    "    # Get the current working directory as base directory for the notebook\n",
    "    base_dir = os.getcwd()\n",
    "    \n",
    "    # Adjust the project root path relatively to where the notebook is located\n",
    "    # Assuming the notebook is inside a 'notebooks' directory and we need to go up one level to access project root\n",
    "    project_root = os.path.join(base_dir, '..')\n",
    "\n",
    "# Clean output of cell\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set the correct path for the NPZ file\n",
    "data_path = os.path.join(project_root, 'dataapp_domain_train_test_sets.npz')\n",
    "\n",
    "# Load the dataset from the NPZ file\n",
    "data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "# Extract the training and testing sets\n",
    "X_train = data['X_train']  \n",
    "X_test = data['X_test'] \n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "print('Data loaded successfully.')\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ],
   "id": "bd48a92e09961fda",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "X_train shape: (215257, 244)\n",
      "X_test shape: (92254, 244)\n",
      "y_train shape: (215257,)\n",
      "y_test shape: (92254,)\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.Hyperparameter Tuning via GridSearchCV and Imbalanced-learn Pipeline",
   "id": "cbe789d731d07bcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Set Up Resampling Techniques**: Define over-sampling (SMOTE) and under-sampling (RandomUnderSampler) methods to handle class imbalance in the dataset.\n",
    "2. **Initialize Models**: Create instances of RandomForestClassifier and RidgeClassifier for classification tasks.\n",
    "3. **Define Hyperparameter Grids**: Specify parameter grids for tuning hyperparameters of the classifiers using GridSearchCV.\n",
    "4. **Create Pipelines**: Construct pipelines to integrate resampling techniques with the classifiers.\n",
    "5. **Perform Hyperparameter Tuning**: Use GridSearchCV to find the best hyperparameters and resampling techniques for each classifier, evaluating them using cross-validation and storing the best models."
   ],
   "id": "6ea95384359ab660"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T17:03:35.464881Z",
     "start_time": "2024-06-12T16:57:51.364168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # Random Forest is a good choice for classification tasks\n",
    "from sklearn.linear_model import RidgeClassifier # Ridge Classifier is a linear model suitable for classification tasks\n",
    "from sklearn.model_selection import GridSearchCV # GridSearchCV for hyperparameter tuning and cross-validation\n",
    "from imblearn.pipeline import Pipeline # Pipeline for chaining resampling techniques with the classifier\n",
    "from imblearn.over_sampling import SMOTE # SMOTE for over-sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler # RandomUnderSampler for under-sampling\n",
    "\n",
    "# Define the resampling techniques\n",
    "over_sampler = SMOTE(random_state=42)\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Define the models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "ridge = RidgeClassifier()\n",
    "\n",
    "# Define the parameter grids for GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200], # Number of trees in the forest\n",
    "    'classifier__max_depth': [10, 20], # Maximum depth of the tree\n",
    "    'classifier__class_weight': [None, 'balanced'] # Weights associated with classes in the form {class_label: weight}\n",
    "}\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'classifier__alpha': [1.0, 0.1, 0.01], # Regularization strength\n",
    "    'classifier__class_weight': [None, 'balanced'] # Weights associated with classes in the form {class_label: weight}\n",
    "}\n",
    "\n",
    "# Define pipelines\n",
    "pipeline_rf_over = Pipeline([\n",
    "    ('oversample', over_sampler), \n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "pipeline_rf_under = Pipeline([\n",
    "    ('undersample', under_sampler),\n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "pipeline_rf_weight = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_ridge_over = Pipeline([\n",
    "    ('oversample', over_sampler),\n",
    "    ('classifier', ridge)\n",
    "])\n",
    "\n",
    "pipeline_ridge_under = Pipeline([\n",
    "    ('undersample', under_sampler),\n",
    "    ('classifier', ridge)\n",
    "])\n",
    "\n",
    "pipeline_ridge_weight = Pipeline([\n",
    "    ('classifier', RidgeClassifier(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Perform GridSearchCV for each pipeline\n",
    "# pipeline is a sequence of fit-transform steps ending with a fit\n",
    "# Store the best estimators in a dictionary\n",
    "\n",
    "grids = [\n",
    "    (pipeline_rf_over, param_grid_rf, 'Random Forest with Over-sampling'), # \n",
    "    (pipeline_rf_under, param_grid_rf, 'Random Forest with Under-sampling'),\n",
    "    (pipeline_rf_weight, param_grid_rf, 'Random Forest with Class Weight'),\n",
    "    (pipeline_ridge_over, param_grid_ridge, 'Ridge with Over-sampling'),\n",
    "    (pipeline_ridge_under, param_grid_ridge, 'Ridge with Under-sampling'),\n",
    "    (pipeline_ridge_weight, param_grid_ridge, 'Ridge with Class Weight')\n",
    "]\n",
    "\n",
    "best_estimators = {} # Dictionary to store the best estimators\n",
    "\n",
    "for pipeline, param_grid, name in grids:\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimators[name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best ROC AUC for {name}: {grid_search.best_score_}\")\n",
    "\n"
   ],
   "id": "60e72a82bf47abaa",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 72>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pipeline, param_grid, name \u001B[38;5;129;01min\u001B[39;00m grids:\n\u001B[0;32m     73\u001B[0m     grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mpipeline, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 74\u001B[0m     \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m     best_estimators[name] \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest parameters for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrid_search\u001B[38;5;241m.\u001B[39mbest_params_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    871\u001B[0m     )\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1378\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1379\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    819\u001B[0m         )\n\u001B[0;32m    820\u001B[0m     )\n\u001B[1;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    844\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\joblib\\parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\joblib\\parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[0;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\concurrent\\futures\\_base.py:441\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m--> 441\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[0;32m    444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2a3892f08444ed43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation of the Results A modifier!!!!!!!!!!!!!\n",
    "\n",
    "#### Summary\n",
    "\n",
    "1. **Random Forest with Over-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__class_weight': None, 'classifier__max_depth': 20, 'classifier__n_estimators': 200}`\n",
    "   - **Best ROC AUC**: `0.706770540515098`\n",
    "\n",
    "2. **Random Forest with Under-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__class_weight': None, 'classifier__max_depth': 20, 'classifier__n_estimators': 200}`\n",
    "   - **Best ROC AUC**: `0.739534466894729`\n",
    "\n",
    "3. **Ridge with Over-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__alpha': 1.0, 'classifier__class_weight': None}`\n",
    "   - **Best ROC AUC**: `0.745725332792906`\n",
    "\n",
    "4. **Ridge with Under-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__alpha': 1.0, 'classifier__class_weight': None}`\n",
    "   - **Best ROC AUC**: `0.7446270382358854`\n",
    "\n",
    "#### Observations\n",
    "\n",
    "1. **Random Forest**:\n",
    "   - The best parameters for both over-sampling and under-sampling are the same, suggesting that the model configuration is robust across different resampling strategies.\n",
    "   - The ROC AUC for under-sampling (0.7395) is higher than for over-sampling (0.7068), indicating that under-sampling might be a better strategy for the Random Forest model in this case.\n",
    "\n",
    "2. **Ridge Classifier**:\n",
    "   - The best parameters for both over-sampling and under-sampling are the same.\n",
    "   - The ROC AUC values are very close for over-sampling (0.7457) and under-sampling (0.7446), indicating that both resampling strategies perform similarly well for the Ridge Classifier.\n",
    "\n",
    "#### Warnings\n",
    "\n",
    "The warnings you received:\n",
    "```\n",
    "C:\\Users\\pat\\.conda\\envs\\P4\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=7.51842e-18): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "\n",
    "C:\\Users\\pat\\.conda\\envs\\P4\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:212: LinAlgWarning: Ill-conditioned matrix (rcond=6.55936e-17): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "```\n",
    "These warnings indicate that the Ridge regression encountered ill-conditioned matrices, which means that the matrix used in the ridge regression solver has very small singular values, causing potential numerical instability. This can happen when there are highly correlated features in the dataset.\n",
    "\n",
    "#### Recommendations\n",
    "\n",
    "1. **Addressing Ill-Conditioned Matrix Warnings**:\n",
    "   - **Feature Engineering**: Investigate and possibly remove or combine highly correlated features to reduce multicollinearity.\n",
    "   - **Regularization**: Consider using stronger regularization (increase the `alpha` parameter) to help stabilize the solution.\n",
    "   - **Scaling**: Ensure that the features are properly scaled, as Ridge regression can be sensitive to the scale of the features.\n",
    "\n",
    "2. **Model Selection**:\n",
    "   - **Ridge Classifier**: Given the higher ROC AUC scores, the Ridge Classifier seems to perform better than the Random Forest in this case.\n",
    "   - **Resampling Strategy**: Both over-sampling and under-sampling show similar performance for the Ridge Classifier, but under-sampling performs better for Random Forest. You might choose the strategy based on other factors such as computational efficiency or interpretability.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Model Evaluation**:\n",
    "   - Evaluate the best models on the test set using confusion matrix, ROC AUC, and other metrics.\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - Use SHAP or similar methods to interpret the models and understand the importance of different features.\n",
    "\n",
    "3. **Documentation and Reporting**:\n",
    "   - Document the findings, including the best parameters, ROC AUC scores, and any observations regarding the resampling strategies and model performance."
   ],
   "id": "1243d29a0c120335"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.Evaluate the Best Model",
   "id": "97552594f71e4aeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Select the Best Model**: Identify and select the best model from the hyperparameter-tuned models stored in `best_estimators` based on their performance on the test set.\n",
    "2. **Make Predictions**: Use the selected best model to predict the target variable on the test dataset.\n",
    "3. **Evaluate Performance**: Calculate the confusion matrix and ROC AUC score to assess the model's performance on the test data.\n",
    "4. **Check for Overfitting**: Ensure that the ROC AUC score is below 0.82 to avoid overfitting, issuing a warning if the score is higher.\n",
    "5. **Generate Detailed Metrics**: Print a comprehensive classification report including precision, recall, and F1-score for a detailed evaluation of the model's performance."
   ],
   "id": "3208e4b1a5c980ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
    "\n",
    "# Select the best model (for example purposes, choosing the best model based on GridSearchCV results)\n",
    "best_model_name = max(best_estimators, key=lambda name: best_estimators[name].score(X_test, y_test))\n",
    "best_model = best_estimators[best_model_name]\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "\n",
    "# Ensure ROC AUC < 0.82\n",
    "if roc_auc >= 0.82:\n",
    "    print(\"Warning: ROC AUC score is greater than or equal to 0.82. Model might be overfitting.\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "id": "858811dfb9290b86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4.Feature Importance",
   "id": "898a240d06f7cede"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 Global Feature Importance Using SHAP",
   "id": "b834e8e4483a1c8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Initialize SHAP Explainer**: Create a SHAP explainer object for the best model's classifier using the training data.\n",
    "2. **Compute SHAP Values**: Generate SHAP values for the test dataset to explain the model's predictions.\n",
    "3. **Global Feature Importance**: Visualize the global feature importance using SHAP summary plot, which provides insights into how each feature contributes to the model's predictions."
   ],
   "id": "d4be0141f61189d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Fit the explainer on the training data\n",
    "explainer = shap.Explainer(best_model['classifier'], X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Global feature importance\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ],
   "id": "f1ce1736161f6514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 Local Feature Importance Using SHAP",
   "id": "f06f82d571f049c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Initialize SHAP Visualization**: Set up SHAP's JavaScript visualization framework to enable interactive plots.\n",
    "2. **Generate Local Explanation**: Create a SHAP force plot for a single instance from the test dataset, showing how each feature contributes to the model's prediction for that specific instance.\n",
    "3. **Visualize Prediction Breakdown**: Provide a detailed breakdown of the prediction for the selected instance, illustrating the impact of each feature on the predicted value."
   ],
   "id": "187a45cda5219c68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Fit the explainer on the training data\n",
    "explainer = shap.Explainer(best_model['classifier'], X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Global feature importance\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "# Local explanation for a single instance\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test[0,:])\n",
    "\n"
   ],
   "id": "2a6e4f12273dd616",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Glossary\n",
    "\n",
    "### Cross-Validation\n",
    "A technique used to assess the performance of a model by splitting the dataset into multiple training and testing sets. This helps in understanding how the model will generalize to an independent dataset.\n",
    "\n",
    "### GridSearchCV\n",
    "A tool from `scikit-learn` that performs hyperparameter tuning by exhaustively searching through a specified parameter grid to find the best combination of hyperparameters for a given model, using cross-validation.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "The process of finding the optimal values for hyperparameters of a model, which are parameters that are not learned from data but set before the learning process begins. Examples include the number of trees in a random forest or the regularization strength in Ridge regression.\n",
    "\n",
    "### ROC AUC Score\n",
    "A performance measurement for classification problems at various threshold settings. ROC AUC represents the area under the Receiver Operating Characteristic curve, which plots the true positive rate against the false positive rate. A score closer to 1 indicates better performance.\n",
    "\n",
    "### Confusion Matrix\n",
    "A table used to describe the performance of a classification model by showing the actual vs. predicted classifications. It includes True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
    "\n",
    "### Classification Report\n",
    "A detailed report showing the precision, recall, F1-score, and support for each class in a classification problem. This helps in understanding the performance of the model across different classes.\n",
    "\n",
    "### Resampling Techniques\n",
    "Methods used to adjust the class distribution of a dataset, commonly used to handle class imbalance. Examples include:\n",
    "- **SMOTE (Synthetic Minority Over-sampling Technique)**: Generates synthetic samples for the minority class.\n",
    "- **RandomUnderSampler**: Reduces the number of samples in the majority class.\n",
    "\n",
    "### Pipeline\n",
    "A tool from `scikit-learn` that allows for chaining multiple processing steps (e.g., data transformation and model fitting) into a single object. This ensures that all steps are applied consistently during both training and testing.\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations)\n",
    "A method to explain individual predictions of machine learning models by assigning each feature an importance value. It helps in understanding how the model arrives at its predictions.\n",
    "\n",
    "### SHAP Explainer\n",
    "An object in the SHAP library that is used to calculate SHAP values for a given model. It helps in interpreting the contributions of each feature to the predictions.\n",
    "\n",
    "### SHAP Values\n",
    "Values calculated by the SHAP explainer that quantify the contribution of each feature to the model's prediction for a given instance. Higher absolute values indicate greater impact on the prediction.\n",
    "\n",
    "### SHAP Summary Plot\n",
    "A plot that visualizes the global importance of features by showing the distribution of SHAP values for each feature across all instances in the dataset. It helps in understanding which features are most influential for the model.\n",
    "\n",
    "### SHAP Force Plot\n",
    "A plot that provides a detailed breakdown of the contributions of each feature to a single instance's prediction, illustrating how different features push the prediction towards or away from the base value.\n",
    "\n",
    "### Random Forest\n",
    "An ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
    "\n",
    "### Ridge Classifier\n",
    "A linear model for classification that includes L2 regularization (Ridge regression) to prevent overfitting by penalizing large coefficients.\n",
    "\n",
    "### Class Weight\n",
    "A parameter used to handle class imbalance by assigning different weights to different classes, typically to give more importance to the minority class. This can be set to 'balanced' to automatically adjust weights inversely proportional to class frequencies.\n",
    "\n",
    "### RandomUnderSampler\n",
    "A resampling technique that reduces the number of instances in the majority class by randomly sampling without replacement, used to balance the class distribution.\n",
    "\n",
    "### SMOTE\n",
    "A resampling technique that generates synthetic samples for the minority class by interpolating between existing minority class instances. It is used to balance the class distribution in the dataset.\n"
   ],
   "id": "27de101d1c04a5e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
