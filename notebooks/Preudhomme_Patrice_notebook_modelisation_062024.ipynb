{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Load the Preprocessed Data",
   "id": "458083ce2249405a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import gc\n",
    "\n",
    "# Indicate if the script is running on Google Colab or not\n",
    "using_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if using_colab:\n",
    "    # Connect Google Drive to Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    \n",
    "    # Install necessary packages\n",
    "    !pip install numpy\n",
    "    !pip install pandas\n",
    "    !pip install sklearn\n",
    "    !pip install matplotlib\n",
    "    !pip install seaborn\n",
    "    !pip install imbalanced-learn\n",
    "    !pip install shap\n",
    "    \n",
    "    # Path for Google Colab\n",
    "    project_root = '/content/gdrive/MyDrive/oc_projet_4/' \n",
    "else:\n",
    "    # Get the current working directory as base directory for the notebook\n",
    "    base_dir = os.getcwd()\n",
    "    \n",
    "    # Adjust the project root path relatively to where the notebook is located\n",
    "    # Assuming the notebook is inside a 'notebooks' directory and we need to go up one level to access project root\n",
    "    project_root = os.path.join(base_dir, '..')\n",
    "\n",
    "# Clean output of cell\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "# Load the CSV files\n",
    "train_domain_path = os.path.join(project_root, 'data', 'app_train_domain.csv')\n",
    "test_domain_path = os.path.join(project_root, 'data', 'app_test_domain.csv')\n",
    "\n",
    "app_train_domain = pd.read_csv(train_domain_path) # Load the training data\n",
    "app_test_domain = pd.read_csv(test_domain_path) # Load the test data\n",
    "\n",
    "# Extract the training and testing sets\n",
    "X_train = app_train_domain.drop(columns=['TARGET']).values # Features for training\n",
    "y_train = app_train_domain['TARGET'].values # Target variable for training\n",
    "X_test = app_test_domain.values  # Assuming test set does not have TARGET column\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Data loaded successfully.')\n",
    "print(f'X_train shape: {X_train.shape}') # X_train is used for training the model\n",
    "print(f'X_val shape: {X_val_split.shape}') # X_val is used for validation during training\n",
    "print(f'X_test shape: {X_test.shape}') # X_test is the test set for which predictions are made\n",
    "print(f'y_train shape: {y_train.shape}') # y_train is the target variable for training\n",
    "print(f'y_val shape: {y_val_split.shape}') # y_val is the target variable for validation\n"
   ],
   "id": "bd48a92e09961fda",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "X_train shape: (307511, 247)\n",
      "X_val shape: (61503, 247)\n",
      "X_test shape: (48744, 248)\n",
      "y_train shape: (307511,)\n",
      "y_val shape: (61503,)\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:45:27.507154Z",
     "start_time": "2024-06-17T13:45:27.479128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the first few values of y_train\n",
    "print('First 10 values of y_train:', y_train[:10])\n",
    "\n",
    "# Check the unique values in y_train\n",
    "print('Unique values in y_train:', np.unique(y_train))\n",
    "\n",
    "# Check for missing values in y_train\n",
    "print('Number of missing values in y_train:', pd.Series(y_train).isnull().sum())"
   ],
   "id": "e3ec5c9abc0dbc05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 values of y_train: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Unique values in y_train: [0. 1.]\n",
      "Number of missing values in y_train: 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:45:27.679480Z",
     "start_time": "2024-06-17T13:45:27.509155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the first few rows of the training data\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_train sample values: {y_train[:5]}\")  # Afficher les premières valeurs pour vérification\n",
    "\n",
    "# Display the columns of X_train to verify the features\n",
    "x_train_columns = list(app_train_domain.drop(columns=['TARGET']).columns)\n",
    "print(f\"X_train columns: {x_train_columns}\")\n",
    "\n",
    "# List of new features to check\n",
    "new_features = ['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']\n",
    "\n",
    "# Check if these new features are in X_train columns\n",
    "missing_features = [feature for feature in new_features if feature not in x_train_columns]\n",
    "\n",
    "if not missing_features:\n",
    "    print(\"All new features are present in X_train.\")\n",
    "else:\n",
    "    print(f\"Missing features in X_train: {missing_features}\")\n"
   ],
   "id": "27c15317a12bdd7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (307511,)\n",
      "y_train sample values: [1. 0. 0. 0. 0.]\n",
      "X_train columns: ['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'CODE_GENDER_F', 'CODE_GENDER_M', 'CODE_GENDER_XNA', 'NAME_TYPE_SUITE_Children', 'NAME_TYPE_SUITE_Family', 'NAME_TYPE_SUITE_Group of people', 'NAME_TYPE_SUITE_Other_A', 'NAME_TYPE_SUITE_Other_B', 'NAME_TYPE_SUITE_Spouse, partner', 'NAME_TYPE_SUITE_Unaccompanied', 'NAME_INCOME_TYPE_Businessman', 'NAME_INCOME_TYPE_Commercial associate', 'NAME_INCOME_TYPE_Maternity leave', 'NAME_INCOME_TYPE_Pensioner', 'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Student', 'NAME_INCOME_TYPE_Unemployed', 'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Academic degree', 'NAME_EDUCATION_TYPE_Higher education', 'NAME_EDUCATION_TYPE_Incomplete higher', 'NAME_EDUCATION_TYPE_Lower secondary', 'NAME_EDUCATION_TYPE_Secondary / secondary special', 'NAME_FAMILY_STATUS_Civil marriage', 'NAME_FAMILY_STATUS_Married', 'NAME_FAMILY_STATUS_Separated', 'NAME_FAMILY_STATUS_Single / not married', 'NAME_FAMILY_STATUS_Unknown', 'NAME_FAMILY_STATUS_Widow', 'NAME_HOUSING_TYPE_Co-op apartment', 'NAME_HOUSING_TYPE_House / apartment', 'NAME_HOUSING_TYPE_Municipal apartment', 'NAME_HOUSING_TYPE_Office apartment', 'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents', 'OCCUPATION_TYPE_Accountants', 'OCCUPATION_TYPE_Cleaning staff', 'OCCUPATION_TYPE_Cooking staff', 'OCCUPATION_TYPE_Core staff', 'OCCUPATION_TYPE_Drivers', 'OCCUPATION_TYPE_HR staff', 'OCCUPATION_TYPE_High skill tech staff', 'OCCUPATION_TYPE_IT staff', 'OCCUPATION_TYPE_Laborers', 'OCCUPATION_TYPE_Low-skill Laborers', 'OCCUPATION_TYPE_Managers', 'OCCUPATION_TYPE_Medicine staff', 'OCCUPATION_TYPE_Private service staff', 'OCCUPATION_TYPE_Realty agents', 'OCCUPATION_TYPE_Sales staff', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Security staff', 'OCCUPATION_TYPE_Waiters/barmen staff', 'WEEKDAY_APPR_PROCESS_START_FRIDAY', 'WEEKDAY_APPR_PROCESS_START_MONDAY', 'WEEKDAY_APPR_PROCESS_START_SATURDAY', 'WEEKDAY_APPR_PROCESS_START_SUNDAY', 'WEEKDAY_APPR_PROCESS_START_THURSDAY', 'WEEKDAY_APPR_PROCESS_START_TUESDAY', 'WEEKDAY_APPR_PROCESS_START_WEDNESDAY', 'ORGANIZATION_TYPE_Advertising', 'ORGANIZATION_TYPE_Agriculture', 'ORGANIZATION_TYPE_Bank', 'ORGANIZATION_TYPE_Business Entity Type 1', 'ORGANIZATION_TYPE_Business Entity Type 2', 'ORGANIZATION_TYPE_Business Entity Type 3', 'ORGANIZATION_TYPE_Cleaning', 'ORGANIZATION_TYPE_Construction', 'ORGANIZATION_TYPE_Culture', 'ORGANIZATION_TYPE_Electricity', 'ORGANIZATION_TYPE_Emergency', 'ORGANIZATION_TYPE_Government', 'ORGANIZATION_TYPE_Hotel', 'ORGANIZATION_TYPE_Housing', 'ORGANIZATION_TYPE_Industry: type 1', 'ORGANIZATION_TYPE_Industry: type 10', 'ORGANIZATION_TYPE_Industry: type 11', 'ORGANIZATION_TYPE_Industry: type 12', 'ORGANIZATION_TYPE_Industry: type 13', 'ORGANIZATION_TYPE_Industry: type 2', 'ORGANIZATION_TYPE_Industry: type 3', 'ORGANIZATION_TYPE_Industry: type 4', 'ORGANIZATION_TYPE_Industry: type 5', 'ORGANIZATION_TYPE_Industry: type 6', 'ORGANIZATION_TYPE_Industry: type 7', 'ORGANIZATION_TYPE_Industry: type 8', 'ORGANIZATION_TYPE_Industry: type 9', 'ORGANIZATION_TYPE_Insurance', 'ORGANIZATION_TYPE_Kindergarten', 'ORGANIZATION_TYPE_Legal Services', 'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Military', 'ORGANIZATION_TYPE_Mobile', 'ORGANIZATION_TYPE_Other', 'ORGANIZATION_TYPE_Police', 'ORGANIZATION_TYPE_Postal', 'ORGANIZATION_TYPE_Realtor', 'ORGANIZATION_TYPE_Religion', 'ORGANIZATION_TYPE_Restaurant', 'ORGANIZATION_TYPE_School', 'ORGANIZATION_TYPE_Security', 'ORGANIZATION_TYPE_Security Ministries', 'ORGANIZATION_TYPE_Self-employed', 'ORGANIZATION_TYPE_Services', 'ORGANIZATION_TYPE_Telecom', 'ORGANIZATION_TYPE_Trade: type 1', 'ORGANIZATION_TYPE_Trade: type 2', 'ORGANIZATION_TYPE_Trade: type 3', 'ORGANIZATION_TYPE_Trade: type 4', 'ORGANIZATION_TYPE_Trade: type 5', 'ORGANIZATION_TYPE_Trade: type 6', 'ORGANIZATION_TYPE_Trade: type 7', 'ORGANIZATION_TYPE_Transport: type 1', 'ORGANIZATION_TYPE_Transport: type 2', 'ORGANIZATION_TYPE_Transport: type 3', 'ORGANIZATION_TYPE_Transport: type 4', 'ORGANIZATION_TYPE_University', 'ORGANIZATION_TYPE_XNA', 'FONDKAPREMONT_MODE_not specified', 'FONDKAPREMONT_MODE_org spec account', 'FONDKAPREMONT_MODE_reg oper account', 'FONDKAPREMONT_MODE_reg oper spec account', 'HOUSETYPE_MODE_block of flats', 'HOUSETYPE_MODE_specific housing', 'HOUSETYPE_MODE_terraced house', 'WALLSMATERIAL_MODE_Block', 'WALLSMATERIAL_MODE_Mixed', 'WALLSMATERIAL_MODE_Monolithic', 'WALLSMATERIAL_MODE_Others', 'WALLSMATERIAL_MODE_Panel', 'WALLSMATERIAL_MODE_Stone, brick', 'WALLSMATERIAL_MODE_Wooden', 'EMERGENCYSTATE_MODE_No', 'EMERGENCYSTATE_MODE_Yes', 'DAYS_EMPLOYED_ANOM', 'CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']\n",
      "All new features are present in X_train.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:45:27.805991Z",
     "start_time": "2024-06-17T13:45:27.682478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify the data types and missing values in the training data\n",
    "print(app_train_domain.dtypes)\n",
    "print(app_train_domain.isnull().sum())\n"
   ],
   "id": "4bdac84c3299f277",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR                  int64\n",
      "TARGET                    float64\n",
      "NAME_CONTRACT_TYPE          int64\n",
      "FLAG_OWN_CAR                int64\n",
      "FLAG_OWN_REALTY             int64\n",
      "                           ...   \n",
      "DAYS_EMPLOYED_ANOM           bool\n",
      "CREDIT_INCOME_PERCENT     float64\n",
      "ANNUITY_INCOME_PERCENT    float64\n",
      "CREDIT_TERM               float64\n",
      "DAYS_EMPLOYED_PERCENT     float64\n",
      "Length: 248, dtype: object\n",
      "SK_ID_CURR                0\n",
      "TARGET                    0\n",
      "NAME_CONTRACT_TYPE        0\n",
      "FLAG_OWN_CAR              0\n",
      "FLAG_OWN_REALTY           0\n",
      "                         ..\n",
      "DAYS_EMPLOYED_ANOM        0\n",
      "CREDIT_INCOME_PERCENT     0\n",
      "ANNUITY_INCOME_PERCENT    0\n",
      "CREDIT_TERM               0\n",
      "DAYS_EMPLOYED_PERCENT     0\n",
      "Length: 248, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T13:45:36.051492Z",
     "start_time": "2024-06-17T13:45:27.807942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, zscore\n",
    "\n",
    "using_colab = 'google.colab' in sys.modules\n",
    "\n",
    "if using_colab:\n",
    "    # Load the CSV files using relative paths\n",
    "    train_domain_path = os.path.join(project_root, 'data', 'app_train_domain.csv')\n",
    "    test_domain_path = os.path.join(project_root, 'data', 'app_test_domain.csv')\n",
    "else:\n",
    "# Get the current working directory as base directory for the notebook\n",
    "    base_dir = os.getcwd()\n",
    "    \n",
    "    # Adjust the project root path relatively to where the notebook is located\n",
    "    # Assuming the notebook is inside a 'notebooks' directory and we need to go up one level to access project root\n",
    "    project_root = os.path.join(base_dir, '..')\n",
    "\n",
    "# Load the CSV files using relative paths\n",
    "train_domain_path = os.path.join(project_root, 'data', 'app_train_domain.csv')\n",
    "test_domain_path = os.path.join(project_root, 'data', 'app_test_domain.csv')\n",
    "\n",
    "train_data = pd.read_csv(train_domain_path)  # Load the training data\n",
    "test_data = pd.read_csv(test_domain_path)    # Load the test data\n",
    "\n",
    "# Features to analyze\n",
    "features_to_analyze = [\n",
    "    'CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM',\n",
    "    'DAYS_EMPLOYED_PERCENT', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'\n",
    "]\n",
    "\n",
    "# Shapiro-Wilk Test for normality\n",
    "def test_normality(df, features):\n",
    "    normality_results = {}\n",
    "    for feature in features:\n",
    "        stat, p = shapiro(df[feature].dropna())  # Ignore missing values for the test\n",
    "        normality_results[feature] = {'Statistic': stat, 'p-value': p, 'Normal': p > 0.05}\n",
    "    return normality_results\n",
    "\n",
    "# Detecting outliers using z-score\n",
    "def detect_outliers(df, features):\n",
    "    outliers_results = {}\n",
    "    for feature in features:\n",
    "        z_scores = zscore(df[feature].dropna())  # Ignore missing values for z-score calculation\n",
    "        outliers = np.where(np.abs(z_scores) > 3)[0]  # Outliers with z-score > 3\n",
    "        outliers_results[feature] = df[feature].iloc[outliers]\n",
    "    return outliers_results\n",
    "\n",
    "# Execute the functions\n",
    "normality_results = test_normality(train_data, features_to_analyze)\n",
    "outliers_results = detect_outliers(train_data, features_to_analyze)\n",
    "\n",
    "# Display the results\n",
    "print(\"Normality Test Results (Shapiro-Wilk):\")\n",
    "for feature, result in normality_results.items():\n",
    "    print(f\"{feature}: Statistic={result['Statistic']}, p-value={result['p-value']}, Normal={result['Normal']}\")\n",
    "\n",
    "print(\"\\nDetected Outliers:\")\n",
    "for feature, outliers in outliers_results.items():\n",
    "    print(f\"{feature}: {len(outliers)} outliers\")\n",
    "    print(outliers)\n"
   ],
   "id": "41eb48546b60ab7a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 307511.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality Test Results (Shapiro-Wilk):\n",
      "CREDIT_INCOME_PERCENT: Statistic=0.8683387382469063, p-value=7.017665490743911e-144, Normal=False\n",
      "ANNUITY_INCOME_PERCENT: Statistic=0.9120356975923316, p-value=1.7391184523648002e-131, Normal=False\n",
      "CREDIT_TERM: Statistic=0.8813492261004188, p-value=1.2529197766384718e-140, Normal=False\n",
      "DAYS_EMPLOYED_PERCENT: Statistic=0.8455920689876675, p-value=6.2034854179349085e-149, Normal=False\n",
      "EXT_SOURCE_1: Statistic=0.8413734001601811, p-value=8.494600632668699e-150, Normal=False\n",
      "EXT_SOURCE_2: Statistic=0.9267468129817444, p-value=4.763031590479468e-126, Normal=False\n",
      "EXT_SOURCE_3: Statistic=0.9644152629779538, p-value=9.85564431307928e-106, Normal=False\n",
      "DAYS_BIRTH: Statistic=0.9696564518865638, p-value=1.709357664268864e-101, Normal=False\n",
      "\n",
      "Detected Outliers:\n",
      "CREDIT_INCOME_PERCENT: 4340 outliers\n",
      "176       12.835714\n",
      "270       13.754462\n",
      "371       13.611000\n",
      "380       12.112000\n",
      "678       34.916667\n",
      "            ...    \n",
      "307369    13.742400\n",
      "307401    12.729433\n",
      "307443    16.217176\n",
      "307476    13.052667\n",
      "307480    16.666667\n",
      "Name: CREDIT_INCOME_PERCENT, Length: 4340, dtype: float64\n",
      "ANNUITY_INCOME_PERCENT: 3792 outliers\n",
      "60        0.483275\n",
      "678       1.373917\n",
      "719       0.494467\n",
      "733       0.504385\n",
      "779       0.761000\n",
      "            ...   \n",
      "307247    0.486640\n",
      "307363    0.735692\n",
      "307405    0.533727\n",
      "307443    0.582471\n",
      "307480    0.487333\n",
      "Name: ANNUITY_INCOME_PERCENT, Length: 3792, dtype: float64\n",
      "CREDIT_TERM: 106 outliers\n",
      "7474      0.121201\n",
      "7619      0.121292\n",
      "7753      0.124429\n",
      "13055     0.124428\n",
      "15537     0.121201\n",
      "            ...   \n",
      "289178    0.124428\n",
      "297906    0.121500\n",
      "297961    0.121388\n",
      "300090    0.124414\n",
      "300382    0.121388\n",
      "Name: CREDIT_TERM, Length: 106, dtype: float64\n",
      "DAYS_EMPLOYED_PERCENT: 6975 outliers\n",
      "49       -0.521408\n",
      "95       -0.527185\n",
      "127      -0.529192\n",
      "249      -0.517723\n",
      "259      -0.625676\n",
      "            ...   \n",
      "307397   -0.531505\n",
      "307408   -0.529349\n",
      "307413   -0.591815\n",
      "307502   -0.543859\n",
      "307508   -0.529266\n",
      "Name: DAYS_EMPLOYED_PERCENT, Length: 6975, dtype: float64\n",
      "EXT_SOURCE_1: 1593 outliers\n",
      "0         0.083037\n",
      "128       0.053183\n",
      "297       0.068260\n",
      "415       0.084902\n",
      "470       0.040684\n",
      "            ...   \n",
      "306896    0.065634\n",
      "307027    0.081045\n",
      "307126    0.072247\n",
      "307338    0.932105\n",
      "307448    0.073452\n",
      "Name: EXT_SOURCE_1, Length: 1593, dtype: float64\n",
      "EXT_SOURCE_2: 0 outliers\n",
      "Series([], Name: EXT_SOURCE_2, dtype: float64)\n",
      "EXT_SOURCE_3: 0 outliers\n",
      "Series([], Name: EXT_SOURCE_3, dtype: float64)\n",
      "DAYS_BIRTH: 0 outliers\n",
      "Series([], Name: DAYS_BIRTH, dtype: int64)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Analysis and Interpretation\n",
    "\n",
    "#### Normality Test Results (Shapiro-Wilk)\n",
    "\n",
    "The Shapiro-Wilk test was applied to each feature to assess normality. Here are the results:\n",
    "\n",
    "- **CREDIT_INCOME_PERCENT**: Statistic=0.868, p-value=7.018e-144, Normal=False\n",
    "- **ANNUITY_INCOME_PERCENT**: Statistic=0.912, p-value=1.739e-131, Normal=False\n",
    "- **CREDIT_TERM**: Statistic=0.881, p-value=1.253e-140, Normal=False\n",
    "- **DAYS_EMPLOYED_PERCENT**: Statistic=0.846, p-value=6.203e-149, Normal=False\n",
    "- **EXT_SOURCE_1**: Statistic=0.841, p-value=8.495e-150, Normal=False\n",
    "- **EXT_SOURCE_2**: Statistic=0.927, p-value=4.763e-126, Normal=False\n",
    "- **EXT_SOURCE_3**: Statistic=0.964, p-value=9.856e-106, Normal=False\n",
    "- **DAYS_BIRTH**: Statistic=0.970, p-value=1.709e-101, Normal=False\n",
    "\n",
    "**Interpretation**:\n",
    "- All the p-values are significantly smaller than 0.05, which means that none of the features follow a normal distribution. This suggests that standardization (which assumes normality) may not be the best preprocessing step. Instead, other scaling methods like Min-Max Scaling or Robust Scaler may be more appropriate.\n",
    "\n",
    "#### Detected Outliers\n",
    "\n",
    "The z-score method was used to detect outliers in each feature. Here are the results:\n",
    "\n",
    "- **CREDIT_INCOME_PERCENT**: 4340 outliers\n",
    "- **ANNUITY_INCOME_PERCENT**: 3792 outliers\n",
    "- **CREDIT_TERM**: 106 outliers\n",
    "- **DAYS_EMPLOYED_PERCENT**: 6975 outliers\n",
    "- **EXT_SOURCE_1**: 1593 outliers\n",
    "- **EXT_SOURCE_2**: 0 outliers\n",
    "- **EXT_SOURCE_3**: 0 outliers\n",
    "- **DAYS_BIRTH**: 0 outliers\n",
    "\n",
    "**Interpretation**:\n",
    "- **CREDIT_INCOME_PERCENT**, **ANNUITY_INCOME_PERCENT**, **DAYS_EMPLOYED_PERCENT**, and **EXT_SOURCE_1** have a significant number of outliers. This indicates that these features have extreme values which could potentially skew the results of the analysis or modeling.\n",
    "- **EXT_SOURCE_2**, **EXT_SOURCE_3**, and **DAYS_BIRTH** do not have any outliers detected with the z-score method, suggesting these features are more stable and less prone to extreme values.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "Given these findings, here are some recommendations for preprocessing and modeling:\n",
    "\n",
    "1. **Normalization/Scaling**:\n",
    "   - Since the features do not follow a normal distribution, consider using **Min-Max Scaling** or **Robust Scaler** instead of standardization. Robust Scaler is particularly useful for features with many outliers as it scales the data using statistics that are robust to outliers.\n",
    "\n",
    "2. **Handling Outliers**:\n",
    "   - For features with significant outliers, consider applying techniques such as:\n",
    "     - **Winsorizing**: Capping the extreme values.\n",
    "     - **Transformation**: Applying log, square root, or other transformations to reduce the effect of outliers.\n",
    "     - **Removal**: Removing data points that are identified as outliers, although this should be done cautiously to avoid losing valuable information.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Investigate if some of these outliers are due to data entry errors or other anomalies that can be corrected.\n",
    "   - For features with many outliers, you can create additional features that capture the presence of outliers, e.g., a binary feature indicating if a value is an outlier or not.\n",
    "\n",
    "4. **Modeling**:\n",
    "   - Use models that are less sensitive to outliers, such as tree-based methods (e.g., Random Forest, Gradient Boosting) which are generally more robust to outliers.\n",
    "   - Ensure that you have robust cross-validation practices to evaluate the impact of these preprocessing steps.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Implement Min-Max Scaling or Robust Scaling on the features.\n",
    "- Apply outlier handling techniques as needed.\n",
    "- Re-evaluate the performance of your model with these preprocessing steps.\n",
    "- Ensure that your evaluation metrics align with the business goals, such as minimizing the cost of prediction errors as outlined in your project requirements.\n",
    "\n",
    "By following these recommendations, you can ensure that your data preprocessing is robust and your models are well-prepared to handle the characteristics of your dataset."
   ],
   "id": "3168660548360e50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.Hyperparameter Tuning via GridSearchCV and Imbalanced-learn Pipeline",
   "id": "cbe789d731d07bcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Set Up Resampling Techniques**: Define over-sampling (SMOTE) and under-sampling (RandomUnderSampler) methods to handle class imbalance in the dataset.\n",
    "2. **Initialize Models**: Create instances of RandomForestClassifier and RidgeClassifier for classification tasks.\n",
    "3. **Define Hyperparameter Grids**: Specify parameter grids for tuning hyperparameters of the classifiers using GridSearchCV.\n",
    "4. **Create Pipelines**: Construct pipelines to integrate resampling techniques with the classifiers.\n",
    "5. **Perform Hyperparameter Tuning**: Use GridSearchCV to find the best hyperparameters and resampling techniques for each classifier, evaluating them using cross-validation and storing the best models."
   ],
   "id": "6ea95384359ab660"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:22:18.684034Z",
     "start_time": "2024-06-17T13:45:36.053497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "# Define the resampling techniques\n",
    "over_sampler = SMOTE(random_state=42)  # Over-sampling method\n",
    "under_sampler = RandomUnderSampler(random_state=42)  # Under-sampling method\n",
    "\n",
    "# Define the models\n",
    "rf = RandomForestClassifier(random_state=42)  # Random Forest Classifier\n",
    "ridge = RidgeClassifier()  # Create an instance of the Ridge Classifier\n",
    "\n",
    "# Define the parameter grids for GridSearchCV\n",
    "param_grid_rf = {  # Parameter grid for Random Forest\n",
    "    'classifier__n_estimators': [100, 200],  # Number of trees in the forest\n",
    "    'classifier__max_depth': [10, 20]  # Maximum depth of the tree\n",
    "}\n",
    "\n",
    "param_grid_ridge = {  # Parameter grid for Ridge Classifier\n",
    "    'classifier__alpha': [1.0, 0.1, 0.01]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Define pipelines with Robust Scaling\n",
    "pipeline_rf_over = Pipeline([  # Pipeline for Random Forest with over-sampling\n",
    "    ('scaler', RobustScaler()),  # Robust Scaling\n",
    "    ('oversample', over_sampler),  # Over-sampling method\n",
    "    ('classifier', rf)  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "pipeline_rf_under = Pipeline([  # Pipeline for Random Forest with under-sampling\n",
    "    ('scaler', RobustScaler()),  # Robust Scaling\n",
    "    ('undersample', under_sampler),  # Under-sampling method\n",
    "    ('classifier', rf)  # Random Forest Classifier\n",
    "])\n",
    "\n",
    "pipeline_rf_weight = Pipeline([  # Pipeline for Random Forest with class weight adjustment\n",
    "    ('scaler', RobustScaler()),  # Robust Scaling\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))  # Random Forest Classifier with class weight adjustment\n",
    "])\n",
    "\n",
    "pipeline_ridge_over = Pipeline([  # Pipeline for Ridge Classifier with over-sampling\n",
    "    ('scaler', RobustScaler()),  # Robust Scaling\n",
    "    ('oversample', over_sampler),  # Over-sampling method\n",
    "    ('classifier', ridge)  # Ridge Classifier\n",
    "])\n",
    "\n",
    "pipeline_ridge_under = Pipeline([  # Pipeline for Ridge Classifier with under-sampling\n",
    "    ('scaler', RobustScaler()),  # Robust Scaling\n",
    "    ('undersample', under_sampler),  # Under-sampling method\n",
    "    ('classifier', ridge)  # Ridge Classifier\n",
    "])\n",
    "\n",
    "pipeline_ridge_weight = Pipeline([  # Pipeline for Ridge Classifier with class weight adjustment\n",
    "    ('scaler', RobustScaler()),  # Robust Scaling\n",
    "    ('classifier', RidgeClassifier(class_weight='balanced'))  # Ridge Classifier with class weight adjustment\n",
    "])\n",
    "\n",
    "# Function to compute ROC AUC for models with or without predict_proba\n",
    "def compute_roc_auc(model, X, y):\n",
    "    if hasattr(model, \"predict_proba\"): # Check if the model has predict_proba attribute\n",
    "        y_proba = model.predict_proba(X)[:, 1] # Get the probability of the positive class\n",
    "    elif hasattr(model, \"decision_function\"): # Check if the model has decision_function attribute\n",
    "        y_proba = model.decision_function(X) # Get the decision function scores\n",
    "    else:\n",
    "        y_proba = model.predict(X) # Use the model's predictions as the scores\n",
    "    return roc_auc_score(y, y_proba) # Compute ROC AUC score\n",
    "\n",
    "# Perform GridSearchCV for each pipeline and store the best estimators\n",
    "grids = [\n",
    "    (pipeline_rf_over, param_grid_rf, 'Random Forest with Over-sampling'), # pipeline, parameter grid, name\n",
    "    (pipeline_rf_under, param_grid_rf, 'Random Forest with Under-sampling'),\n",
    "    (pipeline_rf_weight, param_grid_rf, 'Random Forest with Class Weight'),\n",
    "    (pipeline_ridge_over, param_grid_ridge, 'Ridge with Over-sampling'),\n",
    "    (pipeline_ridge_under, param_grid_ridge, 'Ridge with Under-sampling'),\n",
    "    (pipeline_ridge_weight, param_grid_ridge, 'Ridge with Class Weight')\n",
    "]\n",
    "\n",
    "best_estimators = {}  # Dictionary to store the best estimators\n",
    "roc_auc_scores = {}  # Dictionary to store the ROC AUC scores for each model\n",
    "\n",
    "for pipeline, param_grid, name in grids:  # Iterate over the pipelines\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='roc_auc', cv=3, n_jobs=-1)  # GridSearchCV for hyperparameter tuning\n",
    "    grid_search.fit(X_train_split, y_train_split)  # Fit the model for training data\n",
    "    best_estimators[name] = grid_search.best_estimator_  # Store the best estimator\n",
    "    roc_auc = compute_roc_auc(grid_search.best_estimator_, X_val_split, y_val_split)  # Compute ROC AUC on validation set\n",
    "    roc_auc_scores[name] = roc_auc  # Store the ROC AUC score\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")  # Print the best parameters\n",
    "    print(f\"Best ROC AUC for {name}: {roc_auc}\")  # Print the best ROC AUC score\n",
    "\n",
    "# Select the best model based on ROC AUC scores\n",
    "best_model_name = max(roc_auc_scores, key=roc_auc_scores.get) #key is a function that defines the sorting criteria\n",
    "best_model = best_estimators[best_model_name] # Get the best model\n",
    "print(f\"\\nBest model: {best_model_name} with ROC AUC: {roc_auc_scores[best_model_name]}\")\n",
    "\n",
    "gc.collect()  # Garbage collection to free up memory. Works only in Jupyter notebooks.\n"
   ],
   "id": "2da7ed3b0c06a1cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest with Over-sampling: {'classifier__max_depth': 20, 'classifier__n_estimators': 200}\n",
      "Best ROC AUC for Random Forest with Over-sampling: 0.7051265054419742\n",
      "Best parameters for Random Forest with Under-sampling: {'classifier__max_depth': 20, 'classifier__n_estimators': 200}\n",
      "Best ROC AUC for Random Forest with Under-sampling: 0.7439398146413645\n",
      "Best parameters for Random Forest with Class Weight: {'classifier__max_depth': 10, 'classifier__n_estimators': 200}\n",
      "Best ROC AUC for Random Forest with Class Weight: 0.7334545861438759\n",
      "Best parameters for Ridge with Over-sampling: {'classifier__alpha': 1.0}\n",
      "Best ROC AUC for Ridge with Over-sampling: 0.7451146797593615\n",
      "Best parameters for Ridge with Under-sampling: {'classifier__alpha': 1.0}\n",
      "Best ROC AUC for Ridge with Under-sampling: 0.7483156966485889\n",
      "Best parameters for Ridge with Class Weight: {'classifier__alpha': 1.0}\n",
      "Best ROC AUC for Ridge with Class Weight: 0.7493240652562565\n",
      "\n",
      "Best model: Ridge with Class Weight with ROC AUC: 0.7493240652562565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation of the Results\n",
    "\n",
    "#### Summary\n",
    "\n",
    "1. **Random Forest with Over-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__max_depth': 20, 'classifier__n_estimators': 200}`\n",
    "   - **Best ROC AUC**: `0.7025714300577274`\n",
    "\n",
    "2. **Random Forest with Under-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__max_depth': 20, 'classifier__n_estimators': 200}`\n",
    "   - **Best ROC AUC**: `0.7393607794366517`\n",
    "\n",
    "3. **Random Forest with Class Weight**:\n",
    "   - **Best Parameters**: `{'classifier__max_depth': 10, 'classifier__n_estimators': 200}`\n",
    "   - **Best ROC AUC**: `0.7284622555457663`\n",
    "\n",
    "4. **Ridge with Over-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__alpha': 1.0}`\n",
    "   - **Best ROC AUC**: `0.7413334928962128`\n",
    "\n",
    "5. **Ridge with Under-sampling**:\n",
    "   - **Best Parameters**: `{'classifier__alpha': 1.0}`\n",
    "   - **Best ROC AUC**: `0.7449914888258974`\n",
    "\n",
    "6. **Ridge with Class Weight**:\n",
    "   - **Best Parameters**: `{'classifier__alpha': 1.0}`\n",
    "   - **Best ROC AUC**: `0.7468065211237337`\n",
    "\n",
    "#### Observations\n",
    "\n",
    "1. **Random Forest**:\n",
    "   - The best parameters for both over-sampling and under-sampling are the same, suggesting that the model configuration is robust across different resampling strategies.\n",
    "   - The ROC AUC for under-sampling (0.7394) is higher than for over-sampling (0.7026), indicating that under-sampling might be a better strategy for the Random Forest model in this case.\n",
    "   - Using class weight adjustment in Random Forest shows an improvement in ROC AUC compared to over-sampling but still underperforms compared to under-sampling.\n",
    "\n",
    "2. **Ridge Classifier**:\n",
    "   - The best parameters for both over-sampling and under-sampling are the same.\n",
    "   - The ROC AUC values are very close for over-sampling (0.7413) and under-sampling (0.7450), indicating that both resampling strategies perform similarly well for the Ridge Classifier.\n",
    "   - Using class weight adjustment in Ridge Classifier gives a slightly better ROC AUC (0.7468), making it the best-performing method overall.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- **Random Forest** performs best with under-sampling, suggesting that reducing the number of majority class samples can help the model learn better.\n",
    "- **Ridge Classifier** performs best with class weight adjustment, indicating that this method handles class imbalance effectively.\n",
    "- Overall, class weight adjustment in the Ridge Classifier achieved the highest ROC AUC, making it the most effective method for this dataset."
   ],
   "id": "75f86ebcee7f818b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.Evaluate the Best Model",
   "id": "97552594f71e4aeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Select the Best Model**: Identify and select the best model from the hyperparameter-tuned models stored in `best_estimators` based on their performance on the test set.\n",
    "2. **Make Predictions**: Use the selected best model to predict the target variable on the test dataset.\n",
    "3. **Evaluate Performance**: Calculate the confusion matrix and ROC AUC score to assess the model's performance on the test data.\n",
    "4. **Check for Overfitting**: Ensure that the ROC AUC score is below 0.82 to avoid overfitting, issuing a warning if the score is higher.\n",
    "5. **Generate Detailed Metrics**: Print a comprehensive classification report including precision, recall, and F1-score for a detailed evaluation of the model's performance."
   ],
   "id": "3208e4b1a5c980ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:22:37.447023Z",
     "start_time": "2024-06-17T14:22:18.686035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
    "\n",
    "# Function to compute ROC AUC for models with or without predict_proba\n",
    "def compute_roc_auc(model, X, y): # Compute ROC AUC for models with or without predict_proba\n",
    "    if hasattr(model, \"predict_proba\"): # Check if the model has predict_proba attribute; predict_proba is used for models like RandomForestClassifier\n",
    "        y_proba = model.predict_proba(X)[:, 1] # Get the probability of the positive class\n",
    "    elif hasattr(model, \"decision_function\"): # Check if the model has decision_function attribute; decision_function is used for models like SVC\n",
    "        y_proba = model.decision_function(X) # Get the decision function scores\n",
    "    else: \n",
    "        y_proba = model.predict(X) # Use the model's predictions as the scores\n",
    "    return roc_auc_score(y, y_proba) # Compute ROC AUC score\n",
    "\n",
    "# Select the best model based on validation ROC AUC score\n",
    "best_model_name = max(best_estimators, key=lambda name: compute_roc_auc(best_estimators[name], X_val_split, y_val_split)) \n",
    "best_model = best_estimators[best_model_name] # Get the best model\n",
    "\n",
    "# Predict the target variable on the validation set\n",
    "y_val_pred = best_model.predict(X_val_split) # Predict the target variable on the validation set\n",
    "y_val_proba = best_model.predict_proba(X_val_split)[:, 1] if hasattr(best_model, \"predict_proba\") else best_model.decision_function(X_val_split) if hasattr(best_model, \"decision_function\") else best_model.predict(X_val_split) # Get the predicted probabilities\n",
    "\n",
    "# Compute confusion matrix for validation set\n",
    "conf_matrix_val = confusion_matrix(y_val_split, y_val_pred)\n",
    "print(\"Confusion Matrix (Validation):\")\n",
    "print(conf_matrix_val)\n",
    "\n",
    "# Compute ROC AUC score for validation set using probabilities\n",
    "roc_auc_val = roc_auc_score(y_val_split, y_val_proba) \n",
    "print(f\"ROC AUC (Validation): {roc_auc_val}\")\n",
    "\n",
    "# Ensure ROC AUC < 0.82 for validation set\n",
    "if roc_auc_val >= 0.82: # Check if ROC AUC score is greater than or equal to 0.82 otherwise issue a warning; 0.82 is a threshold to avoid overfitting\n",
    "    print(\"Warning: ROC AUC score (Validation) is greater than or equal to 0.82. Model might be overfitting.\")\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Classification Report (Validation):\")\n",
    "print(classification_report(y_val_split, y_val_pred))\n",
    "\n"
   ],
   "id": "48852bf3c1dd3250",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Validation):\n",
      "[[39011 17543]\n",
      " [ 1596  3353]]\n",
      "ROC AUC (Validation): 0.7493240652562565\n",
      "Classification Report (Validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.69      0.80     56554\n",
      "         1.0       0.16      0.68      0.26      4949\n",
      "\n",
      "    accuracy                           0.69     61503\n",
      "   macro avg       0.56      0.68      0.53     61503\n",
      "weighted avg       0.90      0.69      0.76     61503\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation of the Results\n",
    "\n",
    "#### Confusion Matrix\n",
    "```\n",
    "Confusion Matrix (Validation):\n",
    "[[39011 17543]\n",
    " [ 1596  3353]]\n",
    "```\n",
    "The confusion matrix shows:\n",
    "- **True Negatives (TN)**: 39,011 (clients correctly identified as not defaulting)\n",
    "- **False Positives (FP)**: 17,543 (clients incorrectly identified as defaulting)\n",
    "- **False Negatives (FN)**: 1,596 (clients incorrectly identified as not defaulting)\n",
    "- **True Positives (TP)**: 3,353 (clients correctly identified as defaulting)\n",
    "\n",
    "#### ROC AUC Score\n",
    "```\n",
    "ROC AUC (Validation): 0.7493240652562565\n",
    "```\n",
    "The ROC AUC score is approximately 0.75, indicating a reasonable ability of the model to distinguish between defaulting and non-defaulting clients.\n",
    "\n",
    "#### Classification Report\n",
    "```\n",
    "Classification Report (Validation):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.69      0.80     56554\n",
    "         1.0       0.16      0.68      0.26      4949\n",
    "\n",
    "    accuracy                           0.69     61503\n",
    "   macro avg       0.56      0.68      0.53     61503\n",
    "weighted avg       0.90      0.69      0.76     61503\n",
    "```\n",
    "- **Class 0 (Non-defaulting clients)**:\n",
    "  - **Precision**: 0.96 (The proportion of clients predicted not to default that actually did not default)\n",
    "  - **Recall**: 0.69 (The proportion of actual non-defaulting clients correctly predicted)\n",
    "  - **F1-Score**: 0.80 (Harmonic mean of precision and recall)\n",
    "  - **Support**: 56,554 (Number of actual non-defaulting clients)\n",
    "\n",
    "- **Class 1 (Defaulting clients)**:\n",
    "  - **Precision**: 0.16 (The proportion of clients predicted to default that actually defaulted)\n",
    "  - **Recall**: 0.68 (The proportion of actual defaulting clients correctly predicted)\n",
    "  - **F1-Score**: 0.26 (Harmonic mean of precision and recall, which is low due to precision being low)\n",
    "  - **Support**: 4,949 (Number of actual defaulting clients)\n",
    "\n",
    "- **Overall Metrics**:\n",
    "  - **Accuracy**: 0.69 (The proportion of total correct predictions)\n",
    "  - **Macro Average**: Average precision, recall, and F1-score for both classes (treating all classes equally)\n",
    "  - **Weighted Average**: Average precision, recall, and F1-score for both classes (considering the support of each class)\n",
    "\n",
    "### Observations and Insights\n",
    "1. **Model Performance**:\n",
    "   - The model shows a significant improvement in recall for defaulting clients (0.68), meaning it identified a large proportion of defaulting clients correctly.\n",
    "   - However, the precision for defaulting clients is quite low (0.16), indicating many false positives.\n",
    "   - The model performs well in predicting non-defaulting clients (Class 0) with high precision (0.96) and reasonable recall (0.69).\n",
    "\n",
    "2. **ROC AUC Score**:\n",
    "   - The ROC AUC score of 0.75 indicates that the model has a good ability to discriminate between defaulting and non-defaulting clients.\n",
    "\n",
    "3. **Imbalance Issue**:\n",
    "   - The model still faces an imbalance issue, as seen in the lower precision for defaulting clients and the disparity between class performances.\n",
    "\n",
    "4. **Need for Improvement**:\n",
    "   - Although the model has improved, there is still room for enhancement, particularly in reducing false positives for defaulting clients.\n",
    "\n",
    "### Recommendations\n",
    "1. **Reassess the Model**:\n",
    "   - Consider fine-tuning the threshold for predicting defaulting clients to balance precision and recall better.\n",
    "   - Explore ensemble methods like balanced random forests or XGBoost with tailored class weights to further address class imbalance.\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Further investigate and refine feature engineering to enhance model performance. Creating more relevant features can help the model differentiate better between classes.\n",
    "\n",
    "3. **Evaluate Data**:\n",
    "   - Ensure data quality and consider additional preprocessing steps, such as handling outliers and scaling features appropriately, to improve model performance.\n",
    "\n",
    "4. **Post-Processing**:\n",
    "   - Implement post-processing steps like cost-sensitive learning to account for the higher cost of false negatives, which could further improve decision-making.\n",
    "\n",
    "By continuing to refine the handling of class imbalance, feature engineering, and model evaluation, the model's ability to predict both defaulting and non-defaulting clients can be significantly enhanced."
   ],
   "id": "8e96b1ab04fa3037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:22:48.304867Z",
     "start_time": "2024-06-17T14:22:37.451025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb # Import the LightGBM model\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report # Import metrics for evaluation\n",
    "\n",
    "# Initialize the LightGBM model with class weight to handle imbalance\n",
    "lgbm_model = lgb.LGBMClassifier(random_state=42, class_weight='balanced') # LightGBM model with class weight adjustment\n",
    "\n",
    "# Fit the model for validation set\n",
    "lgbm_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = lgbm_model.predict(X_val_split)\n",
    "\n",
    "# Compute confusion matrix for validation set\n",
    "conf_matrix_val = confusion_matrix(y_val_split, y_val_pred)\n",
    "print(\"Confusion Matrix (Validation) with LightGBM:\")\n",
    "print(conf_matrix_val)\n",
    "\n",
    "# Compute ROC AUC score for validation set\n",
    "roc_auc_val = roc_auc_score(y_val_split, y_val_pred)\n",
    "print(f\"ROC AUC (Validation) with LightGBM: {roc_auc_val}\")\n",
    "\n",
    "# Print classification report for validation set\n",
    "print(\"Classification Report (Validation) with LightGBM:\")\n",
    "print(classification_report(y_val_split, y_val_pred))\n"
   ],
   "id": "fcf72a03a396885d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19876, number of negative: 226132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12731\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 236\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Confusion Matrix (Validation) with LightGBM:\n",
      "[[40247 16307]\n",
      " [ 1559  3390]]\n",
      "ROC AUC (Validation) with LightGBM: 0.6983214911558947\n",
      "Classification Report (Validation) with LightGBM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.71      0.82     56554\n",
      "         1.0       0.17      0.68      0.28      4949\n",
      "\n",
      "    accuracy                           0.71     61503\n",
      "   macro avg       0.57      0.70      0.55     61503\n",
      "weighted avg       0.90      0.71      0.77     61503\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpretation of the Results\n",
    "\n",
    "#### Summary of Results\n",
    "\n",
    "1. **Confusion Matrix**\n",
    "```\n",
    "Confusion Matrix (Validation) with LightGBM:\n",
    "[[40247 16307]\n",
    " [ 1559  3390]]\n",
    "```\n",
    "- **True Negatives (TN)**: 40,247 (clients correctly identified as not defaulting)\n",
    "- **False Positives (FP)**: 16,307 (clients incorrectly identified as defaulting)\n",
    "- **False Negatives (FN)**: 1,559 (clients incorrectly identified as not defaulting)\n",
    "- **True Positives (TP)**: 3,390 (clients correctly identified as defaulting)\n",
    "\n",
    "2. **ROC AUC Score**\n",
    "```\n",
    "ROC AUC (Validation) with LightGBM: 0.6983214911558947\n",
    "```\n",
    "- The ROC AUC score of 0.698 indicates that the model has a reasonable discriminative ability between the classes (default vs. non-default).\n",
    "\n",
    "3. **Classification Report**\n",
    "```\n",
    "Classification Report (Validation) with LightGBM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.71      0.82     56554\n",
    "         1.0       0.17      0.68      0.28      4949\n",
    "\n",
    "    accuracy                           0.71     61503\n",
    "   macro avg       0.57      0.70      0.55     61503\n",
    "weighted avg       0.90      0.71      0.77     61503\n",
    "```\n",
    "- **Class 0 (Non-defaulting clients)**:\n",
    "  - **Precision**: 0.96 (proportion of clients predicted not to default that actually did not default)\n",
    "  - **Recall**: 0.71 (proportion of actual non-defaulting clients correctly predicted)\n",
    "  - **F1-Score**: 0.82 (harmonic mean of precision and recall)\n",
    "  - **Support**: 56,554 (number of actual non-defaulting clients)\n",
    "\n",
    "- **Class 1 (Defaulting clients)**:\n",
    "  - **Precision**: 0.17 (proportion of clients predicted to default that actually defaulted)\n",
    "  - **Recall**: 0.68 (proportion of actual defaulting clients correctly predicted)\n",
    "  - **F1-Score**: 0.28 (harmonic mean of precision and recall)\n",
    "  - **Support**: 4,949 (number of actual defaulting clients)\n",
    "\n",
    "- **Overall Metrics**:\n",
    "  - **Accuracy**: 0.71 (proportion of total correct predictions)\n",
    "  - **Macro Average**: Average precision, recall, and F1-score for both classes (treating all classes equally)\n",
    "  - **Weighted Average**: Average precision, recall, and F1-score for both classes (considering the support of each class)\n",
    "\n",
    "#### Observations and Insights\n",
    "\n",
    "1. **Model Performance**:\n",
    "   - The LightGBM model shows reasonable classification performance with an ROC AUC score of 0.698, indicating moderate discriminative ability between defaulting and non-defaulting clients.\n",
    "   - The high precision for class 0 (0.96) indicates that the model is very good at predicting non-defaulting clients. However, the precision for class 1 (0.17) is low, meaning there are many false positives among the default predictions.\n",
    "\n",
    "2. **Recall for Defaulting Clients (1.0)**:\n",
    "   - The recall for class 1 (0.68) is fairly high, indicating that the model detects a significant proportion of defaulting clients. However, the low precision suggests that many of these positive predictions are incorrect.\n",
    "\n",
    "3. **Class Imbalance**:\n",
    "   - The model is still affected by class imbalance, as evidenced by the disparity in performance metrics between the two classes.\n",
    "   - Using the `class_weight='balanced'` parameter helps improve the recall for the minority class (defaulting clients), but precision remains a challenge.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Improve Class Imbalance Handling**:\n",
    "   - Continue experimenting with different resampling techniques such as SMOTE, under-sampling, or a combination of both.\n",
    "   - Explore other parameters and configurations for LightGBM, such as adjustments to regularization and tree depth.\n",
    "\n",
    "2. **Refine the Model**:\n",
    "   - Conduct a more thorough hyperparameter search to further optimize the model.\n",
    "   - Consider using other robust models for class imbalance, such as XGBoost or ensemble classifiers.\n",
    "\n",
    "3. **Interpret the Results**:\n",
    "   - Use model interpretation techniques such as SHAP to understand which features most influence the model’s predictions and potentially improve feature selection.\n",
    "\n",
    "Focusing on these aspects can further improve the model's ability to better predict defaulting and non-defaulting clients."
   ],
   "id": "a0385274e35fed28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4.Feature Importance",
   "id": "898a240d06f7cede"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 Global Feature Importance Using SHAP",
   "id": "b834e8e4483a1c8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Initialize SHAP Explainer**: Create a SHAP explainer object for the best model's classifier using the training data.\n",
    "2. **Compute SHAP Values**: Generate SHAP values for the test dataset to explain the model's predictions.\n",
    "3. **Global Feature Importance**: Visualize the global feature importance using SHAP summary plot, which provides insights into how each feature contributes to the model's predictions."
   ],
   "id": "d4be0141f61189d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T14:23:33.957738Z",
     "start_time": "2024-06-17T14:22:48.306853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shap  # Import the SHAP library used for interpreting model predictions\n",
    "import pandas as pd  # Import pandas for data manipulation\n",
    "\n",
    "# Convert the data to DataFrame if it's not already one\n",
    "X_train_df = pd.DataFrame(X_train)  # Convert the training data to DataFrame\n",
    "X_val_df = pd.DataFrame(X_val_split)  # Convert the validation data to DataFrame\n",
    "X_test_df = pd.DataFrame(X_test)  # Convert the test data to DataFrame\n",
    "\n",
    "# Function to reduce memory usage by sampling data\n",
    "def reduce_memory_usage(df, sample_fraction=0.1):\n",
    "    \"\"\"Reduces memory usage by sampling a fraction of the data.\"\"\"\n",
    "    return df.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "# Reduce memory usage by sampling\n",
    "X_train_sampled = reduce_memory_usage(X_train_df)\n",
    "X_val_sampled = reduce_memory_usage(X_val_df)\n",
    "X_test_sampled = reduce_memory_usage(X_test_df)\n",
    "\n",
    "# Check and convert categorical variables to numeric\n",
    "X_train_sampled = pd.get_dummies(X_train_sampled)\n",
    "X_val_sampled = pd.get_dummies(X_val_sampled)\n",
    "X_test_sampled = pd.get_dummies(X_test_sampled)\n",
    "\n",
    "# Align the training, validation, and testing data to have the same columns\n",
    "X_train_sampled, X_val_sampled = X_train_sampled.align(X_val_sampled, join='inner', axis=1)\n",
    "X_train_sampled, X_test_sampled = X_train_sampled.align(X_test_sampled, join='inner', axis=1)\n",
    "X_val_sampled, X_test_sampled = X_val_sampled.align(X_test_sampled, join='inner', axis=1)\n",
    "\n",
    "# Ensure the columns are in the same order\n",
    "X_val_sampled = X_val_sampled[X_train_sampled.columns]\n",
    "X_test_sampled = X_test_sampled[X_train_sampled.columns]\n",
    "\n",
    "# Fit the explainer on the training data\n",
    "explainer = shap.Explainer(best_model.named_steps['classifier'], X_train_sampled)\n",
    "shap_values = explainer(X_test_sampled)  # Compute SHAP values for the test data\n",
    "\n",
    "# Global feature importance\n",
    "shap.summary_plot(shap_values, X_test_sampled)  # Visualize the global feature importance using SHAP summary plot\n",
    "\n",
    "# Local explanation for a single instance\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0, :], X_test_sampled.iloc[0, :])\n"
   ],
   "id": "82a2346cb5b384ef",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (247,) and (4108,) not aligned: 247 (dim 0) != 4108 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 34>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     31\u001B[0m X_test_sampled \u001B[38;5;241m=\u001B[39m X_test_sampled[X_train_sampled\u001B[38;5;241m.\u001B[39mcolumns]\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# Fit the explainer on the training data\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m explainer \u001B[38;5;241m=\u001B[39m \u001B[43mshap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExplainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnamed_steps\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclassifier\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train_sampled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m shap_values \u001B[38;5;241m=\u001B[39m explainer(X_test_sampled)  \u001B[38;5;66;03m# Compute SHAP values for the test data\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Global feature importance\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\shap\\explainers\\_explainer.py:191\u001B[0m, in \u001B[0;36mExplainer.__init__\u001B[1;34m(self, model, masker, link, algorithm, output_names, feature_names, linearize_link, seed, **kwargs)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m algorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m \u001B[38;5;241m=\u001B[39m explainers\u001B[38;5;241m.\u001B[39mLinear\n\u001B[1;32m--> 191\u001B[0m     explainers\u001B[38;5;241m.\u001B[39mLinear\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasker, link\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlink, feature_names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_names, linearize_link\u001B[38;5;241m=\u001B[39mlinearize_link, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m algorithm \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeep\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m \u001B[38;5;241m=\u001B[39m explainers\u001B[38;5;241m.\u001B[39mDeep\n",
      "File \u001B[1;32m~\\.conda\\envs\\P4\\lib\\site-packages\\shap\\explainers\\_linear.py:153\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[1;34m(self, model, masker, link, nsamples, feature_perturbation, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected_value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected_value)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected_value \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mM \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmean)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# if needed, estimate the transform matrices\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: shapes (247,) and (4108,) not aligned: 247 (dim 0) != 4108 (dim 0)"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import shap  # Import the SHAP library used for interpreting model predictions\n",
    "# import pandas as pd  # Import pandas for data manipulation\n",
    "# \n",
    "# # Convert the data to a DataFrame if it's not already one\n",
    "# X_train_split_df = pd.DataFrame(X_train_split)  # Convert the training data to a DataFrame\n",
    "# X_val_split_df = pd.DataFrame(X_val_split)  # Convert the validation data to a DataFrame\n",
    "# X_test_df = pd.DataFrame(X_test)  # Convert the test data to a DataFrame\n",
    "# \n",
    "# # Function to reduce memory usage by sampling data\n",
    "# def reduce_memory_usage(df, sample_fraction=0.1):  # Reduce memory usage by sampling to a fraction of the data\n",
    "#     return df.sample(frac=sample_fraction, random_state=42)  # Sample a fraction of the data\n",
    "# \n",
    "# # Reduce memory usage by sampling\n",
    "# X_train_split_df_sampled = reduce_memory_usage(X_train_split_df)  # Sample the training data\n",
    "# X_val_split_df_sampled = reduce_memory_usage(X_val_split_df)  # Sample the validation data\n",
    "# X_test_df_sampled = reduce_memory_usage(X_test_df)  # Sample the test data\n",
    "# \n",
    "# # Check and convert categorical variables to numeric\n",
    "# X_train_split_df_sampled = pd.get_dummies(X_train_split_df_sampled)  # Convert categorical variables to numeric for training data\n",
    "# X_val_split_df_sampled = pd.get_dummies(X_val_split_df_sampled)  # Convert categorical variables to numeric for validation data\n",
    "# X_test_df_sampled = pd.get_dummies(X_test_df_sampled)  # Convert categorical variables to numeric for test data\n",
    "# \n",
    "# # Align the training, validation, and testing data to have the same columns\n",
    "# X_train_split_df_sampled, X_val_split_df_sampled = X_train_split_df_sampled.align(X_val_split_df_sampled, join='inner', axis=1)  # Align the training and validation data\n",
    "# X_train_split_df_sampled, X_test_df_sampled = X_train_split_df_sampled.align(X_test_df_sampled, join='inner', axis=1)  # Align the training and test data\n",
    "# X_val_split_df_sampled, X_test_df_sampled = X_val_split_df_sampled.align(X_test_df_sampled, join='inner', axis=1)  # Align the validation and test data\n",
    "# \n",
    "# # Ensure the columns are in the same order\n",
    "# X_val_split_df_sampled = X_val_split_df_sampled[X_train_split_df_sampled.columns]  # Ensure the columns are in the same order for validation data\n",
    "# X_test_df_sampled = X_test_df_sampled[X_train_split_df_sampled.columns]  # Ensure the columns are in the same order for test data\n",
    "# \n",
    "# # Fit the explainer on the training data\n",
    "# explainer = shap.Explainer(best_model.named_steps['classifier'], X_train_split_df_sampled)  # Fit the SHAP explainer on the training data\n",
    "# shap_values = explainer(X_val_split_df_sampled)  # Compute SHAP values for the validation data\n",
    "# \n",
    "# # Global feature importance\n",
    "# shap.summary_plot(shap_values, X_val_split_df_sampled)  # Visualize the global feature importance using SHAP summary plot\n",
    "# \n",
    "# # Local explanation for a single instance\n",
    "# shap.initjs()  # Initialize the SHAP JavaScript visualization\n",
    "# shap.force_plot(explainer.expected_value, shap_values[0, :], X_val_split_df_sampled.iloc[0, :])  # Generate a SHAP force plot for a single instance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "ecd18ea859ae31f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 Local Feature Importance Using SHAP",
   "id": "f06f82d571f049c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The objective of this code is to:\n",
    "1. **Initialize SHAP Visualization**: Set up SHAP's JavaScript visualization framework to enable interactive plots.\n",
    "2. **Generate Local Explanation**: Create a SHAP force plot for a single instance from the test dataset, showing how each feature contributes to the model's prediction for that specific instance.\n",
    "3. **Visualize Prediction Breakdown**: Provide a detailed breakdown of the prediction for the selected instance, illustrating the impact of each feature on the predicted value."
   ],
   "id": "187a45cda5219c68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Glossary\n",
    "\n",
    "### Cross-Validation\n",
    "A technique used to assess the performance of a model by splitting the dataset into multiple training and testing sets. This helps in understanding how the model will generalize to an independent dataset.\n",
    "\n",
    "### GridSearchCV\n",
    "A tool from `scikit-learn` that performs hyperparameter tuning by exhaustively searching through a specified parameter grid to find the best combination of hyperparameters for a given model, using cross-validation.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "The process of finding the optimal values for hyperparameters of a model, which are parameters that are not learned from data but set before the learning process begins. Examples include the number of trees in a random forest or the regularization strength in Ridge regression.\n",
    "\n",
    "### ROC AUC Score\n",
    "A performance measurement for classification problems at various threshold settings. ROC AUC represents the area under the Receiver Operating Characteristic curve, which plots the true positive rate against the false positive rate. A score closer to 1 indicates better performance.\n",
    "\n",
    "### Confusion Matrix\n",
    "A table used to describe the performance of a classification model by showing the actual vs. predicted classifications. It includes True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
    "\n",
    "### Classification Report\n",
    "A detailed report showing the precision, recall, F1-score, and support for each class in a classification problem. This helps in understanding the performance of the model across different classes.\n",
    "\n",
    "### Resampling Techniques\n",
    "Methods used to adjust the class distribution of a dataset, commonly used to handle class imbalance. Examples include:\n",
    "- **SMOTE (Synthetic Minority Over-sampling Technique)**: Generates synthetic samples for the minority class.\n",
    "- **RandomUnderSampler**: Reduces the number of samples in the majority class.\n",
    "\n",
    "### Pipeline\n",
    "A tool from `scikit-learn` that allows for chaining multiple processing steps (e.g., data transformation and model fitting) into a single object. This ensures that all steps are applied consistently during both training and testing.\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations)\n",
    "A method to explain individual predictions of machine learning models by assigning each feature an importance value. It helps in understanding how the model arrives at its predictions.\n",
    "\n",
    "### SHAP Explainer\n",
    "An object in the SHAP library that is used to calculate SHAP values for a given model. It helps in interpreting the contributions of each feature to the predictions.\n",
    "\n",
    "### SHAP Values\n",
    "Values calculated by the SHAP explainer that quantify the contribution of each feature to the model's prediction for a given instance. Higher absolute values indicate greater impact on the prediction.\n",
    "\n",
    "### SHAP Summary Plot\n",
    "A plot that visualizes the global importance of features by showing the distribution of SHAP values for each feature across all instances in the dataset. It helps in understanding which features are most influential for the model.\n",
    "\n",
    "### SHAP Force Plot\n",
    "A plot that provides a detailed breakdown of the contributions of each feature to a single instance's prediction, illustrating how different features push the prediction towards or away from the base value.\n",
    "\n",
    "### Random Forest\n",
    "An ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
    "\n",
    "### Ridge Classifier\n",
    "A linear model for classification that includes L2 regularization (Ridge regression) to prevent overfitting by penalizing large coefficients.\n",
    "\n",
    "### Class Weight\n",
    "A parameter used to handle class imbalance by assigning different weights to different classes, typically to give more importance to the minority class. This can be set to 'balanced' to automatically adjust weights inversely proportional to class frequencies.\n",
    "\n",
    "### RandomUnderSampler\n",
    "A resampling technique that reduces the number of instances in the majority class by randomly sampling without replacement, used to balance the class distribution.\n",
    "\n",
    "### SMOTE\n",
    "A resampling technique that generates synthetic samples for the minority class by interpolating between existing minority class instances. It is used to balance the class distribution in the dataset.\n"
   ],
   "id": "27de101d1c04a5e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
